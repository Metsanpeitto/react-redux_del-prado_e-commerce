{"id":"../node_modules/webpack/lib/optimize/LimitChunkCountPlugin.js","dependencies":[{"name":"/home/jarri/Desktop/lenovo2020/projects-web/eCommerce/template-store1/package.json","includedInParent":true,"mtime":1594655291184},{"name":"/home/jarri/Desktop/lenovo2020/projects-web/eCommerce/template-store1/node_modules/webpack/package.json","includedInParent":true,"mtime":1594578778161},{"name":"schema-utils","loc":{"line":7,"column":32},"parent":"/home/jarri/Desktop/lenovo2020/projects-web/eCommerce/template-store1/node_modules/webpack/lib/optimize/LimitChunkCountPlugin.js","resolved":"/home/jarri/Desktop/lenovo2020/projects-web/eCommerce/template-store1/node_modules/schema-utils/src/index.js"},{"name":"../../schemas/plugins/optimize/LimitChunkCountPlugin.json","loc":{"line":8,"column":23},"parent":"/home/jarri/Desktop/lenovo2020/projects-web/eCommerce/template-store1/node_modules/webpack/lib/optimize/LimitChunkCountPlugin.js","resolved":"/home/jarri/Desktop/lenovo2020/projects-web/eCommerce/template-store1/node_modules/webpack/schemas/plugins/optimize/LimitChunkCountPlugin.json"},{"name":"../util/LazyBucketSortedSet","loc":{"line":9,"column":36},"parent":"/home/jarri/Desktop/lenovo2020/projects-web/eCommerce/template-store1/node_modules/webpack/lib/optimize/LimitChunkCountPlugin.js","resolved":"/home/jarri/Desktop/lenovo2020/projects-web/eCommerce/template-store1/node_modules/webpack/lib/util/LazyBucketSortedSet.js"}],"generated":{"js":"/*\n\tMIT License http://www.opensource.org/licenses/mit-license.php\n\tAuthor Tobias Koppers @sokra\n*/\n\"use strict\";\n\nfunction _createForOfIteratorHelper(o, allowArrayLike) { var it; if (typeof Symbol === \"undefined\" || o[Symbol.iterator] == null) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = o[Symbol.iterator](); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it.return != null) it.return(); } finally { if (didErr) throw err; } } }; }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nvar validateOptions = require(\"schema-utils\");\n\nvar schema = require(\"../../schemas/plugins/optimize/LimitChunkCountPlugin.json\");\n\nvar LazyBucketSortedSet = require(\"../util/LazyBucketSortedSet\");\n/** @typedef {import(\"../../declarations/plugins/optimize/LimitChunkCountPlugin\").LimitChunkCountPluginOptions} LimitChunkCountPluginOptions */\n\n/** @typedef {import(\"../Chunk\")} Chunk */\n\n/** @typedef {import(\"../Compiler\")} Compiler */\n\n/**\n * @typedef {Object} ChunkCombination\n * @property {boolean} deleted this is set to true when combination was removed\n * @property {number} sizeDiff\n * @property {number} integratedSize\n * @property {Chunk} a\n * @property {Chunk} b\n * @property {number} aIdx\n * @property {number} bIdx\n * @property {number} aSize\n * @property {number} bSize\n */\n\n\nvar addToSetMap = function addToSetMap(map, key, value) {\n  var set = map.get(key);\n\n  if (set === undefined) {\n    map.set(key, new Set([value]));\n  } else {\n    set.add(value);\n  }\n};\n\nvar LimitChunkCountPlugin = /*#__PURE__*/function () {\n  /**\n   * @param {LimitChunkCountPluginOptions=} options options object\n   */\n  function LimitChunkCountPlugin(options) {\n    _classCallCheck(this, LimitChunkCountPlugin);\n\n    if (!options) options = {};\n    validateOptions(schema, options, \"Limit Chunk Count Plugin\");\n    this.options = options;\n  }\n  /**\n   * @param {Compiler} compiler the webpack compiler\n   * @returns {void}\n   */\n\n\n  _createClass(LimitChunkCountPlugin, [{\n    key: \"apply\",\n    value: function apply(compiler) {\n      var options = this.options;\n      compiler.hooks.compilation.tap(\"LimitChunkCountPlugin\", function (compilation) {\n        compilation.hooks.optimizeChunksAdvanced.tap(\"LimitChunkCountPlugin\", function (chunks) {\n          var maxChunks = options.maxChunks;\n          if (!maxChunks) return;\n          if (maxChunks < 1) return;\n          if (chunks.length <= maxChunks) return;\n          var remainingChunksToMerge = chunks.length - maxChunks; // order chunks in a deterministic way\n\n          var orderedChunks = chunks.slice().sort(function (a, b) {\n            return a.compareTo(b);\n          }); // create a lazy sorted data structure to keep all combinations\n          // this is large. Size = chunks * (chunks - 1) / 2\n          // It uses a multi layer bucket sort plus normal sort in the last layer\n          // It's also lazy so only accessed buckets are sorted\n\n          var combinations = new LazyBucketSortedSet( // Layer 1: ordered by largest size benefit\n          function (c) {\n            return c.sizeDiff;\n          }, function (a, b) {\n            return b - a;\n          }, // Layer 2: ordered by smallest combined size\n          function (c) {\n            return c.integratedSize;\n          }, function (a, b) {\n            return a - b;\n          }, // Layer 3: ordered by position difference in orderedChunk (-> to be deterministic)\n          function (c) {\n            return c.bIdx - c.aIdx;\n          }, function (a, b) {\n            return a - b;\n          }, // Layer 4: ordered by position in orderedChunk (-> to be deterministic)\n          function (a, b) {\n            return a.bIdx - b.bIdx;\n          }); // we keep a mappng from chunk to all combinations\n          // but this mapping is not kept up-to-date with deletions\n          // so `deleted` flag need to be considered when iterating this\n\n          /** @type {Map<Chunk, Set<ChunkCombination>>} */\n\n          var combinationsByChunk = new Map();\n          orderedChunks.forEach(function (b, bIdx) {\n            // create combination pairs with size and integrated size\n            for (var aIdx = 0; aIdx < bIdx; aIdx++) {\n              var a = orderedChunks[aIdx];\n              var integratedSize = a.integratedSize(b, options); // filter pairs that do not have an integratedSize\n              // meaning they can NOT be integrated!\n\n              if (integratedSize === false) continue;\n              var aSize = a.size(options);\n              var bSize = b.size(options);\n              var c = {\n                deleted: false,\n                sizeDiff: aSize + bSize - integratedSize,\n                integratedSize,\n                a,\n                b,\n                aIdx,\n                bIdx,\n                aSize,\n                bSize\n              };\n              combinations.add(c);\n              addToSetMap(combinationsByChunk, a, c);\n              addToSetMap(combinationsByChunk, b, c);\n            }\n\n            return combinations;\n          }); // list of modified chunks during this run\n          // combinations affected by this change are skipped to allow\n          // futher optimizations\n\n          /** @type {Set<Chunk>} */\n\n          var modifiedChunks = new Set();\n          var changed = false; // eslint-disable-next-line no-constant-condition\n\n          loop: while (true) {\n            var combination = combinations.popFirst();\n            if (combination === undefined) break;\n            combination.deleted = true;\n            var a = combination.a,\n                b = combination.b,\n                integratedSize = combination.integratedSize; // skip over pair when\n            // one of the already merged chunks is a parent of one of the chunks\n\n            if (modifiedChunks.size > 0) {\n              var queue = new Set(a.groupsIterable);\n\n              var _iterator = _createForOfIteratorHelper(b.groupsIterable),\n                  _step;\n\n              try {\n                for (_iterator.s(); !(_step = _iterator.n()).done;) {\n                  var group = _step.value;\n                  queue.add(group);\n                }\n              } catch (err) {\n                _iterator.e(err);\n              } finally {\n                _iterator.f();\n              }\n\n              var _iterator2 = _createForOfIteratorHelper(queue),\n                  _step2;\n\n              try {\n                for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n                  var _group = _step2.value;\n\n                  var _iterator3 = _createForOfIteratorHelper(modifiedChunks),\n                      _step3;\n\n                  try {\n                    for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n                      var mChunk = _step3.value;\n\n                      if (mChunk !== a && mChunk !== b && mChunk.isInGroup(_group)) {\n                        // This is a potential pair which needs recalculation\n                        // We can't do that now, but it merge before following pairs\n                        // so we leave space for it, and consider chunks as modified\n                        // just for the worse case\n                        remainingChunksToMerge--;\n                        if (remainingChunksToMerge <= 0) break loop;\n                        modifiedChunks.add(a);\n                        modifiedChunks.add(b);\n                        continue loop;\n                      }\n                    }\n                  } catch (err) {\n                    _iterator3.e(err);\n                  } finally {\n                    _iterator3.f();\n                  }\n\n                  var _iterator4 = _createForOfIteratorHelper(_group.parentsIterable),\n                      _step4;\n\n                  try {\n                    for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n                      var parent = _step4.value;\n                      queue.add(parent);\n                    }\n                  } catch (err) {\n                    _iterator4.e(err);\n                  } finally {\n                    _iterator4.f();\n                  }\n                }\n              } catch (err) {\n                _iterator2.e(err);\n              } finally {\n                _iterator2.f();\n              }\n            } // merge the chunks\n\n\n            if (a.integrate(b, \"limit\")) {\n              chunks.splice(chunks.indexOf(b), 1); // flag chunk a as modified as further optimization are possible for all children here\n\n              modifiedChunks.add(a);\n              changed = true;\n              remainingChunksToMerge--;\n              if (remainingChunksToMerge <= 0) break; // Update all affected combinations\n              // delete all combination with the removed chunk\n              // we will use combinations with the kept chunk instead\n\n              var _iterator5 = _createForOfIteratorHelper(combinationsByChunk.get(b)),\n                  _step5;\n\n              try {\n                for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n                  var _combination = _step5.value;\n                  if (_combination.deleted) continue;\n                  _combination.deleted = true;\n                  combinations.delete(_combination);\n                } // Update combinations with the kept chunk with new sizes\n\n              } catch (err) {\n                _iterator5.e(err);\n              } finally {\n                _iterator5.f();\n              }\n\n              var _iterator6 = _createForOfIteratorHelper(combinationsByChunk.get(a)),\n                  _step6;\n\n              try {\n                for (_iterator6.s(); !(_step6 = _iterator6.n()).done;) {\n                  var _combination2 = _step6.value;\n                  if (_combination2.deleted) continue;\n\n                  if (_combination2.a === a) {\n                    // Update size\n                    var newIntegratedSize = a.integratedSize(_combination2.b, options);\n\n                    if (newIntegratedSize === false) {\n                      _combination2.deleted = true;\n                      combinations.delete(_combination2);\n                      continue;\n                    }\n\n                    var finishUpdate = combinations.startUpdate(_combination2);\n                    _combination2.integratedSize = newIntegratedSize;\n                    _combination2.aSize = integratedSize;\n                    _combination2.sizeDiff = _combination2.bSize + integratedSize - newIntegratedSize;\n                    finishUpdate();\n                  } else if (_combination2.b === a) {\n                    // Update size\n                    var _newIntegratedSize = _combination2.a.integratedSize(a, options);\n\n                    if (_newIntegratedSize === false) {\n                      _combination2.deleted = true;\n                      combinations.delete(_combination2);\n                      continue;\n                    }\n\n                    var _finishUpdate = combinations.startUpdate(_combination2);\n\n                    _combination2.integratedSize = _newIntegratedSize;\n                    _combination2.bSize = integratedSize;\n                    _combination2.sizeDiff = integratedSize + _combination2.aSize - _newIntegratedSize;\n\n                    _finishUpdate();\n                  }\n                }\n              } catch (err) {\n                _iterator6.e(err);\n              } finally {\n                _iterator6.f();\n              }\n            }\n          }\n\n          if (changed) return true;\n        });\n      });\n    }\n  }]);\n\n  return LimitChunkCountPlugin;\n}();\n\nmodule.exports = LimitChunkCountPlugin;"},"sourceMaps":null,"error":null,"hash":"8319b224c5c2b51f5f3b041288ddb691","cacheData":{"env":{}}}